{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ecd2c4-b9fc-486b-b14f-0a885f8a50e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parsing the Sagger project data\n",
    "Make sure the **SaggerFlow.articyu3d** file is in the `.\\data\\` subdirectory of current path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229c5abb-2e01-4ed7-8705-e115a89d997f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.join('data','SaggerFlow.articyu3d')\n",
    "if os.path.isfile(path):\n",
    "    print('Success!')    \n",
    "else:\n",
    "    print('It is not, but feel free to look for it with this tiny widget.')\n",
    "    import os, sys\n",
    "    import ipywidgets as widgets\n",
    "    from ipywidgets import Dropdown, Output, HBox,VBox, Button, Text\n",
    "    gui = Output()\n",
    "    gui.layout.border='1px solid black'\n",
    "    \n",
    "    filepath=''\n",
    "    fo = open(r'C:\\Users\\Builder\\Documents\\skrypty\\jupyter-notebooks\\jupyter-parsers\\data\\SaggerFlow.articyu3d', 'r', encoding='utf-8')\n",
    "\n",
    "    root=os.getcwd()\n",
    "    dirs=[root]\n",
    "\n",
    "    out = Output()\n",
    "    t=widgets.Text(value=filepath,disabled=True)\n",
    "    b=Button(description='enter')\n",
    "    w = Dropdown(options=os.listdir(os.path.join(*dirs)))\n",
    "\n",
    "    def onclick(b):\n",
    "        if(b.description == 'enter'):\n",
    "            try:\n",
    "                dirs.append(w.value)\n",
    "                w.options=os.listdir(os.path.join(*dirs))\n",
    "            except:\n",
    "                b.button_style='danger'\n",
    "                t.value = 'something went wrong! please reload the applet.'\n",
    "                b.description = r':('\n",
    "                b.disabled = True\n",
    "                with out:\n",
    "                    out.clear_output()\n",
    "                    display(HBox([t, b]))\n",
    "\n",
    "        elif(b.description == 'select'):\n",
    "            path = os.path.join(*dirs + [w.value])\n",
    "            print(path)\n",
    "            gui.clear_output()\n",
    "            gui.outputs = tuple()\n",
    "            print('Success!')    \n",
    "\n",
    "    b.on_click(onclick)\n",
    "    def on_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            b.description='enter' if (os.path.isdir(os.path.join(*dirs, change['new']))) else 'select'\n",
    "            b.button_style='info'\n",
    "    w.observe(on_change)\n",
    "\n",
    "    with gui:\n",
    "        display(HBox([w,b]))\n",
    "    display(gui)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cd3e7f-a3a4-4c19-bcab-5619c374fd75",
   "metadata": {
    "tags": []
   },
   "source": [
    "Since that file is pretty big, we're going to parse it line by line to avoid memoryleaks with the help of iterators. In other words `lines` is a **generator** object such that eeach `next(lines)` call would yield a new line that can be fed to some pipeline and processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f942b80-9a62-49c9-babb-b7b74165ee13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\n",
      "  \"Settings\": {\n",
      "\n",
      "    \"set_TextFormatter\": \"Plain\",\n",
      "\n",
      "    \"set_IncludedNodes\": \"Settings, Project, GlobalVariables, ObjectDefinitions, Packages, ScriptMethods, Hierarchy, Assets\",\n",
      "\n",
      "    \"set_Localization\": \"False\",\n",
      "\n",
      "    \"set_UseScriptSupport\": \"True\",\n",
      "\n",
      "    \"ExportVersion\": \"1.2\",\n",
      "\n",
      "    \"ObjectDefinitionsHash\": \"69156DE3B5146583EACDB5A1427B03AC8244E99B55B0A26CD7B00D39264DA792\",\n",
      "\n",
      "    \"ScriptFragmentsHash\": \"3215635178\"\n",
      "\n",
      "  },\n",
      "\n",
      "29346773\n"
     ]
    }
   ],
   "source": [
    "lines = (line for line in open(path, encoding='utf-8'))\n",
    "for _ in range(10):\n",
    "    line = next(lines)\n",
    "    print(line)\n",
    "\n",
    "\n",
    "lines = (line for line in open(path, encoding='utf-8'))\n",
    "max_line = sum([1 for _ in lines])\n",
    "\n",
    "#this will take a moment:\n",
    "print(max_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ada48-5aea-4dd3-988b-f54975e3ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = (line for line in open(path, encoding='utf-8'))\n",
    "def simplest_line_parser(l):\n",
    "    print(l)\n",
    "def simple_line_parser(l):\n",
    "    print(l.strip())\n",
    "\n",
    "def process_many(f, batchsize):\n",
    "    for _ in range(batchsize):\n",
    "        f(next(lines))    \n",
    "    print('')\n",
    "        \n",
    "process_many(simplest_line_parser,2)\n",
    "process_many(simple_line_parser,8)\n",
    "\n",
    "# execute this cell to get deeper into the file in order to understand it's structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc5e6a-785d-431f-8cf9-b00d176d8c2d",
   "metadata": {},
   "source": [
    "## File structure\n",
    "The file structure resembles jsons, xmls, or simply dictionaries. In other words it's some kind of a tree â€“ there's clearly one root node with it's child nodes of similar nature. It's not infinite though, so eventually we should encounter a leaf, that is a node without any child nodes. \n",
    "\n",
    "Makes sense, right? But what does a _node_ actually mean? I think we get the idea, so let's try to define that somehow. In order to do that we're going to write the first **grammar rule**. In order for that to be a *proper definition*, any expression following such rule should be a node and vice-versa. \n",
    "Also, it's going to be recursive:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef7277-de18-4e32-888b-6a8c7ed77c49",
   "metadata": {},
   "source": [
    "#### Node definition\n",
    "  $$\\textbf{ N}\\leftrightarrow  \\langle\\textbf{T} , \\textbf{T}\\rangle \\lor \\langle\\textbf{T},[\\textbf{N},\\ldots]\\rangle$$\n",
    "  \n",
    "Any expression **N** is a *node* if and only if it matches one of two following patterns:\n",
    "1. It's a ordered pair of some *terms*, which might be considered as a key-value matching between some strings. Since that node doesn't have any children, then it's a leaf.\n",
    "2. a *term* is paired with a list of *nodes*... these might also be a leaf or the current case type of nodes. \n",
    "\n",
    "##### Why bother? Wasn't that a waste of time?\n",
    "Not at all. Seeing that only two cases need to be considered when parsing an expression might give us some idea about implementing our pipeline structure. Also, the second case clearly suggest that measuring the depth while traversing such nested structures might be in order. It's a clear indicator of child-parent relation between some of the visited nodes. That's handy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65d793-0ea9-4cd3-a60d-95132c58e1f4",
   "metadata": {},
   "source": [
    "## Algorithm overview\n",
    "  Given the `*line [string]*` as an input, which we assume to be a *node*. We should determine which kind of node that might be. If it's a leaf, then simply return `{key:value}` dictionary from it. If it's not, then there's a list of nodes which we might nest into. Simply feed that as a input for that algorithm, leaving the hard work to the recursion. Simply return the `return value` when receiver and it should be done.\n",
    "  \n",
    "#### Implementation\n",
    "Let's start by extracting all possible key-value pairs with their depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e5a1899-0bf1-40cf-9bc2-17ed47753147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParseError(Exception):\n",
    "    def __init__(self, pos, msg, *args):\n",
    "        self.pos = pos\n",
    "        self.msg = msg\n",
    "        self.args = args\n",
    "\n",
    "    def __str__(self):\n",
    "        return '%s at position %s' % (self.msg % self.args, self.pos)\n",
    "\n",
    "class FileParser:\n",
    "    _lock = False\n",
    "    \n",
    "    def __init__(self, path=None, autoFill = True):\n",
    "        self.cache = {}\n",
    "        self.path=path\n",
    "        self.autoFill = autoFill\n",
    "           \n",
    "    @property\n",
    "    def path(self):\n",
    "        return self._path\n",
    "    \n",
    "    @path.setter\n",
    "    def path(self, val):\n",
    "        if not self._lock and val is not None:\n",
    "            self._path = val\n",
    "            lines=(line for line in open(path, encoding='utf-8'))\n",
    "            self.feed=lines\n",
    "        \n",
    "            \n",
    "    @property\n",
    "    def feed(self):\n",
    "        self.current_line += 1\n",
    "\n",
    "        return self._feed\n",
    "    \n",
    "    @feed.setter\n",
    "    def feed(self, val):\n",
    "        self._lock = True\n",
    "        self._feed = val\n",
    "        self.depth = -1\n",
    "        self.current_line = 0\n",
    "        self.allkeys = set()\n",
    "\n",
    "    @feed.deleter\n",
    "    def feed(self):\n",
    "        self._lock = False\n",
    "        if self.autoFill:\n",
    "            path=self.path\n",
    "            self.path=path\n",
    "        else:\n",
    "            del self._feed\n",
    "            \n",
    "    @property\n",
    "    def line(self):\n",
    "        self._line = next(self.feed)\n",
    "        return self._line\n",
    "    @line.setter\n",
    "    def line(self, skip):\n",
    "        for _ in range(1, skip):\n",
    "            self._line=next(self,feed)\n",
    "        return self._line\n",
    "    def find_keys(self, which_keys):\n",
    "        import csv\n",
    "        from datetime import datetime\n",
    "        \n",
    "\n",
    "\n",
    "        lines_gathered=[]\n",
    "        old_depth = -1\n",
    "\n",
    "        for line in self.feed:\n",
    "            depth  = self.getDepth(line)\n",
    "            data = self.trimLine(line)\n",
    "            key=data[0]\n",
    "\n",
    "            if any(k in key for k in which_keys) and (old_depth>depth and old_depth != -1):\n",
    "                old_depth = depth\n",
    "                name=str(key)\n",
    "                prefix=datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "                filename=prefix+name+'.csv'\n",
    "                with open(filename, 'a', encoding='utf-8') as f:\n",
    "                    mywriter = csv.writer(f, delimiter=',').writerows(lines_gathered)\n",
    "                lines_gathered=[data]\n",
    "            elif old_depth!=-1 and old_depth<=depth:\n",
    "                lines_gathered=[data]\n",
    "                \n",
    "                \n",
    "                \n",
    "                    \n",
    "\n",
    "    def process_data(self):\n",
    "        import csv\n",
    "        from datetime import datetime\n",
    "        name='keyvalues_all'\n",
    "        suffix=datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "        filename=name+suffix+'.csv'\n",
    "        with open(filename, 'a', encoding='utf-8') as f:\n",
    "            f.write('key, value, depth\\n') #writing the headers\n",
    "            \n",
    "\n",
    "            for line in self.feed:\n",
    "                depth  = self.getDepth(line)\n",
    "                data = self.trimLine(line)\n",
    "                key=data[0]\n",
    "\n",
    "                if any(ext in data for ext in '{ }'.split()):\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    value=data[1]\n",
    "                except:\n",
    "                    value=data[0]\n",
    "\n",
    "                self.allkeys.add(key)\n",
    "                f.write(', '.join([key, value, str(depth)]))\n",
    "                f.write('\\n')\n",
    "    \n",
    "    def getDepth(self, line):\n",
    "        return int((len(line)-len(line.lstrip()))/2)\n",
    "        \n",
    "    def trimLine(self, line):\n",
    "        import re\n",
    "        data = [re.sub(r'[^{}A-Za-z0-9_\\s]+', '', l) for l in [l.strip() for l in line.split(\":\")]]\n",
    "        return data\n",
    "    \n",
    "    @property\n",
    "    def linecount(self):\n",
    "        try:\n",
    "            return self._linecount\n",
    "        except:\n",
    "            self._linecount = sum([1 for _ in self.feed])\n",
    "            del self.feed\n",
    "            return self._linecount\n",
    "        \n",
    "p = FileParser(path) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b704c30-bea9-4715-a2d3-09f757ce6f6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can extract all the keys available and then search for the interesting ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186faba0-57da-4155-83c3-0e68179977b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# p.linecount\n",
    "p.process_data()\n",
    "\n",
    "import re\n",
    "keys=[]\n",
    "queries=['Tutorial', 'Database', 'Entry']\n",
    "for k in p.allkeys:\n",
    "    if any(q in k for q in queries):\n",
    "        keys.append(k)\n",
    "        \n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e496a14-defb-4c7e-8623-0736e55db73e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keysToLookFor = ['CharacterDatabaseEntry', 'LinkedDatabaseEntries', 'DatabaseEntry', 'CommanderNotebookEntry', 'DatabasePopup', 'DatabaseEntryReference', 'Tutorial', 'TutorialEntry', 'LinkToDatabseEntry', 'DatabaseCategory', 'DatabaseSubcategory', 'EntryName', 'EntryKey']\n",
    "p.find_keys(keysToLookFor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cefd621-4983-4152-86e8-00ccce2b8d8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Sadly we got to the point where it doesn't seem to work yet. Basically it's really tidious due to size of the project with all of the unnecesary files. :/\n",
    "\n",
    "\n",
    "##### bunch of old code that got abadonned @ some point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "df3cf1fb-dd0b-41db-b8c6-0862b60aa6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. [\"Project\"::{] \n",
      "... [\"Name\"::\"GolanWar\",] \n",
      "... [\"DetailName\"::\"\",] \n",
      "... [\"Guid\"::\"08b09661-5911-4dce-b501-5bb3670351c8\",] \n",
      "... [\"TechnicalName\"::\"Saggerflow\"] \n",
      ".. [::},] \n",
      ".. [\"GlobalVariables\"::[] \n",
      "... [::{] \n",
      ".... [\"Namespace\"::\"OLD_Political\",] \n",
      ".... [\"Description\"::\"Political Echosystem Status\",] \n"
     ]
    }
   ],
   "source": [
    "parsed_lines = ([int((len(s)-len(s.lstrip()))/2), *[l.strip() for l in s.split(\":\")]] for s in lines)\n",
    "\n",
    "for _ in range(10):\n",
    "    line=(next(parsed_lines))\n",
    "    try:\n",
    "        trailing_spaces, key, val = line[0], line[1], line[2]\n",
    "    except:\n",
    "        trailing_spaces, key, val = line[0], '', line[1]\n",
    "    \n",
    "    key=key.strip()\n",
    "    val=val.strip()\n",
    "    print('{0} [{1}::{2}] '.format('.'+trailing_spaces*'.', key, val))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8a48cdd-2dd2-4d56-9335-809597af5b53",
   "metadata": {
    "tags": []
   },
   "source": [
    "from ipywidgets import Output, Layout, HBox,VBox, Text, Button, Label\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "_defaultPath = r'C:\\Users\\Builder\\Documents\\skrypty\\jupyter-notebooks\\jupyter-parsers\\data\\SaggerFlow.articyu3d'\n",
    "_defaultQuery='TutorialEntry'\n",
    "\n",
    "# TutorialPopup=dict([('Type', 'TutorialPopup'), ('TechnicalName', ''), ('DisplayName', ''), ('Text', ''), ('Title', '')])\n",
    "\n",
    "wantedKeys={}\n",
    "\n",
    "unwantedTypes = ['Integer', 'Boolean', 'String']\n",
    "queries = ['TutorialEntry']\n",
    "wantedKeys['TutorialEntry'] = ['TechnicalName', 'DisplayName', 'EntryName', 'EntryName, ''Content' ] \n",
    "\n",
    "\n",
    "class parser(VBox):\n",
    "    gui=Output()\n",
    "    _gui=None\n",
    "    results={}\n",
    "    _all_keys=None\n",
    "    current_index =0\n",
    "    current_line =''\n",
    "    output=Output(layout={'width': '100%',\n",
    "                                'height': '160px',\n",
    "                                'border': '1px solid black'})\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def all_keys(self):\n",
    "        if self._all_keys is None:\n",
    "            self.getKeys()\n",
    "        else:\n",
    "            return self._all_keys\n",
    "        \n",
    "    @all_keys.setter\n",
    "    def all_keys(self,keys):\n",
    "        if self._all_keys is None:\n",
    "            self._all_keys = keys\n",
    "        else:\n",
    "            raise Exception('all_keys were already set!')\n",
    "            \n",
    "      \n",
    "    @property\n",
    "    def query(self):\n",
    "        return self._query\n",
    "        \n",
    "    @query.setter\n",
    "    def query(self,q):\n",
    "        self._query = q\n",
    "      \n",
    "                    \n",
    "    def __init__(self, path, query=None):\n",
    "        assert(os.path.isfile(path))\n",
    "        clear_output()\n",
    "        \n",
    "        self.path = path\n",
    "        self.query=query\n",
    "        self.clear_logger()\n",
    "        super().__init__(self.gui())\n",
    "        \n",
    "    def getLine(self,*args):\n",
    "        self.current_line=next(self.plines)\n",
    "        self.current_index+=1\n",
    "        \n",
    "    def setupHeader(self):\n",
    "        b0 = Button(description='set path')\n",
    "        t1=Text(value=self.path, layout={'width': '80%'})\n",
    "        l0 = Button(disabled=True, description='file path')\n",
    "        l0.layout.border='1px solid black'\n",
    "        l0.layout.width='10%'\n",
    "        def handler(b):\n",
    "            new=t1.value\n",
    "            import os\n",
    "            if os.path.isfile(new):\n",
    "                b0.disabled=False\n",
    "                b0.description = 'set path'\n",
    "            else:\n",
    "                b0.disabled=True\n",
    "                \n",
    "        t1.observe(handler, names='value')\n",
    "        \n",
    "        def bhandler(b):\n",
    "            if b.description == 'set path':\n",
    "                new=t1.value\n",
    "                import os\n",
    "                if os.path.isfile(new):\n",
    "                    self.path=new\n",
    "                    b.description = 'init parser'\n",
    "                    b.button_style='warning'\n",
    "\n",
    "                    t1.disabled = True\n",
    "                    \n",
    "                else:\n",
    "                    self.path=''\n",
    "            elif b.description == 'init parser':\n",
    "                self.initParser()\n",
    "                b.description = 'undo'\n",
    "                b.button_style='danger'\n",
    "            elif b.description == 'undo':\n",
    "                t1.disabled = False\n",
    "                b.description = 'set path'\n",
    "                b.button_style='info'\n",
    "                \n",
    "                self.clear_logger()\n",
    "                \n",
    "                \n",
    "        b0.on_click(bhandler)\n",
    "        b0.button_style='info'\n",
    "        \n",
    "        btns_row=HBox([l0, t1, b0])\n",
    "        \n",
    "        header=[btns_row]\n",
    "        self._gui_header = header\n",
    "        return header\n",
    "    def setupCrawler(self):\n",
    "        t1=Output()\n",
    "        \n",
    "        b0 = Button(description='get keys')\n",
    "        b0.on_click(lambda b: t1.output.append_stdout(self.getKeys()))\n",
    "        \n",
    "        btns_row=HBox([b0,t1])\n",
    "        crawler = [btns_row]\n",
    "        self._gui_crawler = crawler\n",
    "        return crawler\n",
    "\n",
    "    def setupFooter(self):\n",
    "        \n",
    "        footer = Button(description='clear log')\n",
    "        footer.on_click(self.clear_logger)\n",
    "        self._gui_footer = [footer]\n",
    "        return self._gui_footer\n",
    "    \n",
    "    \n",
    "    def gui(self):\n",
    "        if self._gui:\n",
    "            return self._gui\n",
    "        else:\n",
    "            self.setupHeader()\n",
    "            self.setupFooter()\n",
    "            self.setupCrawler()\n",
    "        \n",
    "        return [*self._gui_header, *self._gui_crawler, self.output, *self._gui_footer]\n",
    "    def clear_logger(self, *args):\n",
    "        self.output.outputs=()\n",
    "        self.logger('Log cleared', lvl='INFO')\n",
    "    def logger(self, msg, lvl='INFO'):\n",
    "        formatted_record = \"[{}] {}\".format(lvl.upper(), msg)\n",
    "        new_output = {\n",
    "            'name': 'stdout',\n",
    "            'output_type': 'stream',\n",
    "            'text': formatted_record+'\\n'\n",
    "        }\n",
    "        self.output.outputs += (new_output, ) \n",
    "            \n",
    "    def initParser(self, *args):\n",
    "        self.logger(\"[initializing]\", lvl='INFO')\n",
    "        self.logger(\"|-[path]: {0}\".format(self.path))\n",
    "        self.logger(\"|-[query]: {0}\".format(self.query))\n",
    "        self.getLines()\n",
    "        self.logger(\"[ok]\", lvl='INFO')\n",
    "\n",
    "    \n",
    "    def getLines(self, *args):\n",
    "        self.logger(\"[get lines]\")\n",
    "        \n",
    "        self.lines = (line for line in open(self.path, encoding='utf-8'))\n",
    "        self.plines = ([int((len(s)-len(s.lstrip()))/2), *[l.strip() for l in s.split(\":\")]] for s in self.lines)\n",
    "        \n",
    "        self.current_index, rank =0, -1\n",
    "        self.logger(\"[ok]\", lvl='INFO')\n",
    "        \n",
    "    def getKeys(self, *args):\n",
    "        self.logger(\"[get keys]\")\n",
    "        keys = set()\n",
    "        for line in (self.plines):\n",
    "\n",
    "            self.current_index+=1\n",
    "            self.current_line=line\n",
    "            rank, raw_data = line[0], line[1:]\n",
    "            data = [re.sub(r'[^A-Za-z0-9_\\s]+', '', l) for l in raw_data]\n",
    "            self.data=data\n",
    "            try:\n",
    "                value = (data[1:])\n",
    "            except IndexError:\n",
    "                value = None\n",
    "\n",
    "            key=data[0]\n",
    "            keys.add(key)\n",
    "        self.maxLine = self.current_index\n",
    "        self.all_keys = keys\n",
    "        self.logger(\"[ok]\", lvl='INFO')\n",
    "        return keys    \n",
    "#                 print('{0}: {1} [{2}]->({3})'.format(self.current_index, rank, key, value, raw_data))      \n",
    "\n",
    "parser(path=_defaultPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "591d9c56-f611-4926-a731-dd5b5f5ce277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.getAllKes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea2000ac-9199-4bfc-8333-3d9c5136eafa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'parser' object has no attribute 'allKeys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12752/1522285931.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallKeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'parser' object has no attribute 'allKeys'"
     ]
    }
   ],
   "source": [
    "d=set()\n",
    "len(p.allKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb7827f-e15e-4b0d-81d4-02c383372650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
