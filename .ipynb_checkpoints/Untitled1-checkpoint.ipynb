{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acd47378-2c31-4260-9458-7a2f3c2d20e5",
   "metadata": {},
   "source": [
    "## Main Class (Work In Progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4193421-8a93-4712-832e-57d772627506",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sample', 'Dark', 'Reference', 'Scope Corrected for Dark'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from IPython.display import display, clear_output\n",
    "from typing import List, Any, Optional\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "\n",
    "class DisplayAPI(ABC):\n",
    "    @abstractmethod\n",
    "    def display(self):\n",
    "        pass\n",
    "    \n",
    "class Print(DisplayAPI):\n",
    "    def display(self, some_shit):\n",
    "        print(some_shit.data)\n",
    "    \n",
    "class Display(DisplayAPI):\n",
    "    def display(self, some_shit):\n",
    "        display(some_shit.data)\n",
    "    \n",
    "class Pretty(Display):    \n",
    "    def display(self, some_shit):\n",
    "        data = some_shit.data\n",
    "        header = some_shit.header\n",
    "        csv_df = pd.DataFrame(data[:,1:], index=data[:,0], columns=header[1:])\n",
    "        csv_df.index.name=header[0]\n",
    "        display(csv_df)\n",
    "\n",
    "class RawData(ABC):\n",
    "    def __init__(self, file, api: Optional[DisplayAPI] = Display() ) -> None:\n",
    "        self.file = file\n",
    "        self.api = api\n",
    "        \n",
    "        ###\n",
    "        self.get_data(file)\n",
    "     \n",
    "    def display(self):\n",
    "        self.api.display(self)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def get_data(self, file):\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def text(self):\n",
    "        return self.file.read_text()\n",
    "    @property\n",
    "    def lines(self):\n",
    "        return self.text.splitlines()\n",
    "\n",
    "    \n",
    "class CSVFile(RawData):\n",
    "    def get_data(self, file):\n",
    "        self.raw_data= '\\n'.join(self.get_sections()[-1]).encode()\n",
    "        self.data = np.frombuffer(self.raw_data)\n",
    "    \n",
    "    def get_sections(self) -> List[Any]:\n",
    "        indexes = [ *[k for k,line in enumerate(self.lines) if line==''], -1]\n",
    "        return [self.lines[i+1:k] for i,k in zip(indexes[0::2], indexes[1::2])]\n",
    "\n",
    "class Avantes(RawData):\n",
    "    def get_data(self, file, header=(5,3)):\n",
    "        header_line, skip = header\n",
    "        conv=lambda x: x.replace(',', '.').encode()\n",
    "#         conv2 = lambda x: float(x.decode(\"utf-8\").replace(',','.'))\n",
    "\n",
    "        self.header = [x.strip() for x in self.lines[header_line].split(';')]\n",
    "        self.data = np.genfromtxt((conv(x) for x in open(file)),skip_header=header_line+skip, skip_footer=0, delimiter=';')\n",
    "#         self.data = np.genfromtxt(file ,skip_header=header_line+skip, skip_footer=0, delimiter=';', converters = {0: conv2, 1:conv2} )\n",
    "        \n",
    "        \n",
    "class Hitachi(RawData):\n",
    "    def get_data(self, file, header=(30,1)):\n",
    "        header_line, skip = header\n",
    "\n",
    "        self.header = self.lines[header_line].split('\\t')\n",
    "        self.header = [x.strip() for x in self.lines[header_line].split('\\t')]\n",
    "        self.data = np.genfromtxt(file,skip_header=header_line+skip,skip_footer=0) \n",
    "        \n",
    "absorbance_csv =  Path('./patka-pomiary/CPE45_PFOBPy_comocat.txt')\n",
    "fluorescence_csv =  Path('./patka-pomiary/func39.txt')\n",
    "\n",
    "rd = Avantes( file=fluorescence_csv, api=Pretty() ) # api=Display() is set by default \n",
    "rd2 = Hitachi( file=absorbance_csv, api=Pretty() )\n",
    "# rd.display()\n",
    "# rd2.display()\n",
    "\n",
    "data, header = rd.data, rd.header\n",
    "csv_df = pd.DataFrame(data[:,1:], index=data[:,0], columns=header[1:])\n",
    "csv_df.index.name=header[0]\n",
    "# csv_df[csv_df.columns[1:3]].plot()\n",
    "# csv_df.plot()\n",
    "print(csv_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ee9c16-0e2e-4891-8e44-e9cab24ae5b3",
   "metadata": {},
   "source": [
    "### Research & Developement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01527a8f-5b01-402b-85ea-527562befc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\Python\\jupyter notebooks\n"
     ]
    }
   ],
   "source": [
    "## imports and constants:\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib, re\n",
    "from pathlib import Path\n",
    "from ipywidgets import FloatRangeSlider, SelectMultiple, interactive, HTML, HBox, VBox, Textarea\n",
    "from detect_delimiter import detect\n",
    "import pandas as pd \n",
    "\n",
    "print(Path().cwd())\n",
    "# [repr(f) for f in Path('./patka-pomiary/correction.csv').iterdir()]\n",
    "correction_csv =  Path('./patka-pomiary/correction.csv')\n",
    "data_sample_csv =  Path('./patka-pomiary/CPE45_PFOBPy_comocat.txt')\n",
    "data_sample_csv2 =  Path('./patka-pomiary/func39.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c187143d-0e85-4b97-b88f-1a5a2d23a1c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 4), match=' 900'>\n",
      "5 '' True\n",
      "10 '' True\n",
      "28 '' True\n",
      "732 '' True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5, 10, 28, 732]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(\"\\s?(\\d+\\.?\\d+)+\")\n",
    "string1 = data_sample_csv.read_text().splitlines()[7]\n",
    "string2 = data_sample_csv2.read_text().splitlines()[8]\n",
    "\n",
    "matches1 = pattern.match(string1)\n",
    "matches2 = pattern.match(string2)\n",
    "if ( matches1 ):\n",
    "    print(matches1)\n",
    "if ( matches2 ):\n",
    "    print(matches2)\n",
    "    \n",
    "# import csv\n",
    "# with open(data_sample_csv, \"r\") as files:\n",
    "#    reader = csv.reader(files)\n",
    "#    next(reader, None)\n",
    "#    for data in reader:\n",
    "#       print (data)\n",
    "        \n",
    "lines=data_sample_csv.read_text().splitlines()\n",
    "pattern = re.compile(\"\\s*\\t*\\t+\")\n",
    "\n",
    "for k,line in enumerate(lines):\n",
    "    if line.strip() == '' or pattern.match(line.strip()):\n",
    "        print(k, ascii(line), line == '')\n",
    "        \n",
    "[k for k,line in enumerate(lines) if line=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261faf82-7545-46e9-a7ef-ded09c618c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 func39\n",
      "1 Integration time [ms]: 6000,000\n",
      "2 Averaging Nr. [scans]: 3\n",
      "3 Smoothing Nr. [pixels]: 2\n",
      "4 Data measured with spectrometer [name]: NIR\n",
      "5 Wave   ;Sample   ;Dark     ;Reference;Scope Corrected for Dark\n",
      "6 [nm]   ;[counts] ;[counts] ;[counts] \n",
      "7 \n",
      "8  900,12;    0,000;    0,000;    0,000; 0,00000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11700/271048144.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# print(delimeter)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mdelimeter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhitelist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimeter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python39\\lib\\site-packages\\detect_delimiter.py\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(text, default, whitelist, blacklist)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "lines=data_sample_csv2.read_text().splitlines()\n",
    "header=[]\n",
    "pattern = re.compile(\"\\s+(\\d+\\.?\\d+)+\")\n",
    "\n",
    "for k,line in enumerate(lines):\n",
    "    print(k, line)\n",
    "    if ( pattern.match(line) ): \n",
    "        break;\n",
    "    header.append(line)\n",
    "\n",
    "\n",
    "# #     \n",
    "# # \n",
    "# print(delimeter)\n",
    "delimeter = detect(header[-1], whitelist=[';','\\t'], default=',')\n",
    "body=lines[k:]\n",
    "print(k, delimeter)\n",
    "# print(header)\n",
    "# print(body)\n",
    "result = np.genfromtxt(\n",
    "        body,\n",
    "        delimiter=delimeter,\n",
    "    )\n",
    "print(result)\n",
    "#     B = np.genfromtxt(data, delimiter=delimeter)\n",
    "\n",
    "# header = [e for e in line.strip().split('\\t') if e]\n",
    "# print(header)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292c86d-7660-4678-af70-61717969cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def processFile(file, header_line=30, skip=1, skip_footer = 0, *args, **kwargs):\n",
    "    header_start=header_line\n",
    "    header_length=skip\n",
    "    try:\n",
    "        data = file.read_text()\n",
    "        lines = data.splitlines()\n",
    "        header = lines[header_start].split('\\t')\n",
    "        \n",
    "        delimeter = detect(lines[header_start+header_length], whitelist=[';', ',','\\t']) #, default=','\n",
    "#         delimeter = detect(data, whitelist=[';', ',', '\\t'], default=',')\n",
    "\n",
    "        result = np.genfromtxt(\n",
    "            file,\n",
    "            skip_header = header_start+header_length,\n",
    "            skip_footer=skip_footer,\n",
    "            delimiter=delimeter,\n",
    "            dtype=float,\n",
    "        )\n",
    "\n",
    "        if np.isnan(result).all() : \n",
    "            #treat ',' as decimal separator\n",
    "            result = np.genfromtxt(\n",
    "                    (line.replace(',', '.').encode() for line in lines),\n",
    "                    skip_header = header_start+header_length,\n",
    "                    skip_footer=skip_footer,\n",
    "                    delimiter=delimeter,\n",
    "                    dtype=float,\n",
    "                )\n",
    "            \n",
    "        if np.isnan(result).all() :\n",
    "            raise(ValueError('only nans!'))\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(repr(e))\n",
    "# print([str(p) for p in Path('./patka-pomiary/').iterdir()])\n",
    "\n",
    "\n",
    "correction_vector = np.genfromtxt(correction_csv, dtype=float)\n",
    "data_sample = processFile(data_sample_csv2, header_line=30, skip=1, skip_footer = 0)\n",
    "\n",
    "display(pd.DataFrame( data_sample ))\n",
    "# display(data_sample_csv.read_text().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe5aee-223b-40fc-903b-f70be78d9829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install detect_delimiter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d9fcd-e2ce-4103-9de2-b9b14b3deeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in data_sample_csv2.read_text().splitlines():\n",
    "    lineElems = len(line.strip().split(','))\n",
    "    lineElems2 = len(line.strip().split(','))\n",
    "#     line.replace(',', '.').encode()\n",
    "lineElems1 = [((line.strip().split('\\t')) )for line in data_sample_csv.read_text().splitlines()]\n",
    "lineElems2 = [(line.strip().split(',')) for line in data_sample_csv2.read_text().splitlines()]\n",
    "\n",
    "l1max = max([len(l) for l in lineElems1])\n",
    "l2max = max([len(l) for l in lineElems2])\n",
    "\n",
    "[l for l in lineElems1 if len(l)>=l1max]\n",
    "# [l for l in lineElems2 if len(l)>=l2max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe606a50-79f2-48af-afaa-104cbed56890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def processFile(file, conv=lambda x: x.replace(',', '.').encode(), header_start=30, header_length=1):\n",
    "    lines = file.read_text().splitlines()\n",
    "    header = lines[header_start].split('\\t')\n",
    "    \n",
    "    return np.genfromtxt(\n",
    "        file,\n",
    "        skip_header = header_start+header_length,\n",
    "        skip_footer=0,\n",
    "        delimiter=';',\n",
    "        dtype=float,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbef4ff-31d3-45fc-bf04-47c5900d8ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Circle Inversion Fractals (Apollonian Gasket)\n",
    "# FB36 - 20131029\n",
    "# import math\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "imgx = 512; imgy = 512\n",
    "image = Image.new(\"RGB\", (imgx, imgy))\n",
    "pixels = image.load()\n",
    "\n",
    "n = 6 #random.randint(3, 6) # of main circles\n",
    "a = np.pi * 2.0 / n\n",
    "r = np.sin(a) / np.sin((np.pi - a) / 2.0) / 2.0 # r of main circles\n",
    "h = np.sqrt(1.0 - r * r)\n",
    "xa = -h; xb = h; ya = -h; yb = h # viewing area\n",
    "cx = [0.0]; cy = [0.0]; cr = [1.0 - r] # center circle\n",
    "for i in range(n): # add main circles\n",
    "    cx.append(np.cos(a * i))\n",
    "    cy.append(np.sin(a * i))\n",
    "    cr.append(r)\n",
    "maxIt = 100000 # of iterations\n",
    "x = -2.0; y = -2.0 # initial point (outside of the circles)\n",
    "for i in range(maxIt):\n",
    "    k = random.randint(0, n) # selected circle for inversion\n",
    "    dx = x - cx[k]; dy = y - cy[k]\n",
    "    d = np.hypot(dx, dy)\n",
    "\n",
    "    dx = dx / d; dy = dy / d\n",
    "    dnew = cr[k] ** 2.0 / d\n",
    "    x = dnew * dx + cx[k]\n",
    "    y = dnew * dy + cy[k]\n",
    "    kx = int((imgx - 1) * (x - xa) / (xb - xa))\n",
    "    ky = int((imgy - 1) * (y - ya) / (yb - ya))\n",
    "    try: pixels[kx, ky] = (255, 255, 255)\n",
    "    except: pass\n",
    "# image.save(\"CircleInversionFractal_\" + str(n) + \".png\", \"PNG\")\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c935977c-764a-4277-a40a-488dd1c8496d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5cf318-26a4-47ad-940f-a6131ef899fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
